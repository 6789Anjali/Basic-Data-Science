"""
About Dataset
This database contains 34 attributes, 33 of which are linear valued and one of them is nominal.
Number of Instances: 366
Number of Attributes: 34
Feature clinical and histopathological was given a degree in the range of 0 to 3. Here, 0 indicates that the feature was not present, 3 indicates the largest amount possible, and 1, 2 
indicate the relative intermediate values.
"""

#Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#Importing the dataset
df = pd.read_csv('/content/dermatology_database_1.csv')
df.head()

age_values_with_question_mark = df[df['age'] == '?']
age_values_with_question_mark

df['age'] = df['age'].replace('?', np.nan)  # Replace '?' with NaN

# we remove rows with NaN values in the 'age' column using dropna() function
df.dropna(subset=['age'], inplace=True)

age_values_with_question_mark = df[df['age'] == '?']
age_values_with_question_mark

df['age'] = df['age'].astype(float).astype(pd.Int64Dtype())  # Convert to float and then to integer

df.dtypes

df['class'].value_counts()

"""Data Visualization"""

# Plot a bar plot of the 'class' column
class_counts = df['class'].value_counts()
plt.bar(class_counts.index, class_counts.values)
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Class Distribution')
plt.show()

"""
The bar plot is useful for visualizing the frequency or count of different categories in a categorical variable, such as the 'class' column in our DataFrame. By plotting a bar plot, we can
compare the number of instances for each class and gain insights into the class distribution. This visualization can reveal class imbalances, identify dominant or minority classes, or
provide an overview of the distribution of the target variable.
"""

import matplotlib.pyplot as plt
# Plot a histogram of the 'age' column
plt.hist(df['age'], bins=10)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age Distribution')
plt.show()

"""
The histogram allows us to visualize the distribution of a numerical variable, such as the 'age' column in your DataFrame. By plotting a histogram, we can understand the frequency and 
range of ages present in our dataset. This can help identify patterns or anomalies in the age distribution, such as whether it is skewed, normally distributed, or has any significant 
peaks or gaps.
"""

import seaborn as sns
# Calculate the correlation matrix
corr_matrix = df.corr()
corr_matrix
# Plot the correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='Blues')
plt.title('Correlation Heatmap')
plt.show()

"""
The correlation heatmap helps visualize the pairwise correlations between numerical variables in our DataFrame. By calculating the correlation matrix and plotting it as a heatmap, we can
identify the strength and direction of the relationships between different variables. This can assist in understanding the interdependencies between variables and identifying potential 
patterns or associations.
"""

x = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

# Import the necessary class
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y = le.fit_transform(y)

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)

# Feature Scaling
#Since our dataset containing character variables
#we have to encode it using LabelEncoder
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Training the Naive Bayes model on the Training set
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)
print("Predicted Test Results : ",y_pred)
print("~"*20)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
ac = accuracy_score(y_test,y_pred)
print("Model Accuracy : ",ac*100,"%")
print("~"*20)
cm = confusion_matrix(y_test, y_pred)
print("Model Confusion Matrix : ")
print(cm)

# Result Diagnosis
from sklearn.metrics import accuracy_score, confusion_matrix
confusion_matrix(y_pred, y_test)

# Result Diagnosis
model_score = classifier.score(X_test, y_test)
print(model_score)

# Result Diagnosis
y_predictProb = classifier.predict_proba(X_test)
print(y_predictProb)

from sklearn.metrics import auc, roc_curve
from sklearn.preprocessing import label_binarize

# Binarize the labels
y_test_binarized = label_binarize(y_test, classes=range(y_predictProb.shape[1]))

# Iterate over each class and compute ROC curve
for i in range(y_predictProb.shape[1]):
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_predictProb[:, i])
    roc_auc = auc(fpr, tpr)
    print(f"ROC AUC for class {i}: {roc_auc}")

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()





#Link For Google Collab Notebook : https://colab.research.google.com/drive/1pk8oeb-9ok0Fmu1Jbu6hpiCK8TH5guHI?usp=sharing
